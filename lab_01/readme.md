# Project Overview

This project implements a producer-consumer by using Kafka in Python. It consists of producer and consumer scripts that interact with a logging system to track their activities. The project also includes utility functions to handle data structures and loading mechanisms.

The dataset used for this project is laid outside of the project directory

## Directory Structure

```plaintext
.
├── log
│   ├── consumer_Air.log
│   ├── consumer_Earth.log
│   ├── consumer_Water.log
│   ├── producer.log
│
├── producer_consumer
│   ├── consumer.py
│   ├── producer.py
│
├── utils
│   ├── data_class.py
│   ├── loader.py
|
├── docker-compose.yml
|
├── run.py
|
├── requirements.txt
```

## Components

### `producer_consumer/`

- **producer.py**: Responsible for sending data to consumers.

- **consumer.py**: Listens for produced data.

### `utils/`

- **data_class.py**: Defines the data structures used in the model.
- **loader.py**: Handles loading of configurations and data processing utilities.

### `log/`

- Stores log files generated by the producer and consumers.

## Installation & Setup

1. Install dependencies:
   ```sh
   pip install -r requirements.txt  # If applicable
   ```

## Usage

1. Compose the docker-compose.yml
   ```sh
   docker-compose up -d
   ```
2. Run the project
   ```sh
   python run.py
   ```
